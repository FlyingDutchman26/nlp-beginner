{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP -Beginner 任务1 基于机器学习的文本分类\n",
    "实现基于logistic/softmax regression的文本分类\n",
    "1. 参考\n",
    "   1. [文本分类](文本分类.md)\n",
    "   2. 《[神经网络与深度学习](https://nndl.github.io/)》 第2/3章\n",
    "2. 数据集：[Classify the sentiment of sentences from the Rotten Tomatoes dataset](https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews)\n",
    "3. 实现要求：NumPy\n",
    "4. 需要了解的知识点：\n",
    "\n",
    "   1. 文本特征表示：Bag-of-Word，N-gram\n",
    "   2. 分类器：logistic/softmax  regression，损失函数、（随机）梯度下降、特征选择\n",
    "   3. 数据集：训练集/验证集/测试集的划分\n",
    "5. 实验：\n",
    "   1. 分析不同的特征、损失函数、学习率对最终分类性能的影响\n",
    "   2. shuffle 、batch、mini-batch \n",
    "6. 时间：两周"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化 \n",
    "导入相应数据，模块包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import random\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "with open('train.tsv') as f:\n",
    "    tsvreader = csv.reader(f, delimiter='\\t')\n",
    "    temp = list(tsvreader)\n",
    "\n",
    "\n",
    "# 初始化\n",
    "raw_data = temp[1:]  # 忽略了表头\n",
    "raw_data = np.array(raw_data)[:, 2:]\n",
    "max_item = 1000      # 提取前max_item个数据，否则数据量太大 BoWs就有150000*16000的矩阵\n",
    "raw_data = raw_data[:max_item, :]\n",
    "raw_data.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader类\n",
    "目标：实现DataLoader类，将数据集根据Bag of Words 模型或者 N-gram 模型， 转化为特征向量和标签的形式,以X和y返回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 363)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, raw_data, method='BoWs'):\n",
    "        self.raw_data = raw_data\n",
    "        self.method = method\n",
    "        self.words_dict = dict()\n",
    "        self.len = 0\n",
    "        self.X = None\n",
    "        self.y = self.raw_data[:, -1]    # 这是标签\n",
    "        self.N = raw_data.shape[0]    # 数据集的sentence条目\n",
    "\n",
    "    def __call__(self):\n",
    "        self.get_words()\n",
    "        if self.method == 'BoWs':\n",
    "            self.BoWs()\n",
    "        elif self.method == \"N_grams\":\n",
    "            self.N_grams()\n",
    "        else:\n",
    "            raise Exception('Wrong method, please use BoWs or N_grams')\n",
    "        return self.X, self.y\n",
    "\n",
    "    def get_words(self):\n",
    "        '''\n",
    "        统计所有出现的词数量,构建词典\n",
    "        '''\n",
    "        for item in self.raw_data:\n",
    "            s = item[0]\n",
    "            s = s.upper()   # 大小写统一是合理并且必要的\n",
    "            s = s.split()\n",
    "            for word in s:\n",
    "                if word not in self.words_dict:\n",
    "                    # 漂亮的一步（参考）：单词在词典中的值与自然数集对应，从而变为其在特征矩阵中的下表\n",
    "                    self.words_dict[word] = len(self.words_dict)\n",
    "        self.len = len(self.words_dict)\n",
    "        self.X = np.zeros((self.N, self.len))    # 初始化特征矩阵\n",
    "\n",
    "    def BoWs(self):\n",
    "        for i in range(self.N):\n",
    "            s = self.raw_data[i][0]\n",
    "            s = s.upper()\n",
    "            s = s.split()\n",
    "            for word in s:\n",
    "                self.X[i][self.words_dict[word]] += 1\n",
    "\n",
    "    def N_grams():\n",
    "        pass\n",
    "\n",
    "\n",
    "# 测试一下\n",
    "dataloader = DataLoader(raw_data, method='BoWs')\n",
    "X, y = dataloader()\n",
    "print(X.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练集，验证集的分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 363) (200, 363) (800,) (200,)\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "random.seed(521)\n",
    "\n",
    "\n",
    "def train_valid_split(X, y, train_percent=0.8):\n",
    "    '''\n",
    "    输入处理好的数据，随机打乱，返回 X_train, X_valid, y_train, y_valid\n",
    "    '''\n",
    "    n = len(X)\n",
    "    indices = list(range(n))\n",
    "    random.shuffle(indices)\n",
    "    X = X[indices]\n",
    "    y = y[indices]\n",
    "    train_num = int(n*train_percent)\n",
    "    X_train = X[:train_num, :]\n",
    "    X_valid = X[train_num:]\n",
    "    y_train = y[:train_num]\n",
    "    y_valid = y[train_num:]\n",
    "    return X_train, X_valid, y_train, y_valid\n",
    "\n",
    "\n",
    "# 测试一下\n",
    "X_train, X_valid, y_train, y_valid = train_valid_split(X, y)\n",
    "\n",
    "print(X_train.shape, X_valid.shape, y_train.shape, y_valid.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax 函数的定义\n",
    "\n",
    "使用了减去$x_{max}$的方法避免溢出\n",
    "N个（行）向量成批进行处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.09003057 0.24472847 0.66524096]\n",
      " [0.09003057 0.24472847 0.66524096]]\n"
     ]
    }
   ],
   "source": [
    "def softmax(X):\n",
    "    \"\"\"\n",
    "    输入：\n",
    "        - X：shape=[N, C]，N为向量数量，C为向量维度\n",
    "\n",
    "    成批进行softmax运算\n",
    "\n",
    "    使用技巧防止溢出\n",
    "    \"\"\"\n",
    "    x_max = np.max(X, axis=1, keepdims=True)\n",
    "    exp_x = np.exp(X - x_max)\n",
    "    result = exp_x/np.sum(exp_x, axis=1, keepdims=True)\n",
    "    return result\n",
    "\n",
    "\n",
    "# 测试\n",
    "Xt = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(softmax(Xt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax回归模型算子\n",
    "线性函数与softmax函数的结合\n",
    "同样，将N个样本归为一组，成批进行预测\n",
    "#### forward函数\n",
    "$$\n",
    "\\hat{\\mathbf Y} = \\mathrm{softmax}(\\boldsymbol{X} \\boldsymbol{W} + \\mathbf b)\n",
    "$$\n",
    "其中$\\boldsymbol{X}\\in \\mathbb{R}^{N\\times D}$为$N$个样本的特征矩阵，$\\boldsymbol{W}=[\\mathbf w_1,……,\\mathbf w_C]$为$C$个类的权重向量组成的矩阵，$\\hat{\\mathbf Y}\\in \\mathbb{R}^{C}$为所有类别的预测条件概率组成的矩阵。\n",
    "\n",
    "input_dim, output_dim 分别对应的输入向量x的维度，以及预测分类的类别维度。\n",
    "\n",
    "#### backward函数\n",
    "计算风险函数$\\cal R(\\mathbf W,\\mathbf b)$关于参数$\\mathbf W$和$\\mathbf b$的偏导数。在Softmax回归中，计算方法为：\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\cal R(\\mathbf W,\\mathbf b)}{\\partial \\mathbf W} = -\\frac{1}{N}\\sum_{n=1}^N \\mathbf x^{(n)}(y^{(n)}- \\hat{ y}^{(n)})^T = -\\frac{1}{N} \\mathbf X^ \\mathrm{ T } (\\mathbf y- \\hat{\\mathbf y}),（3.17）\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\cal R(\\mathbf W,\\mathbf b)}{\\partial \\mathbf b} = -\\frac{1}{N}\\sum_{n=1}^N (y^{(n)}- \\hat{y}^{(n)})^T = -\\frac{1}{N} \\mathbf 1 (\\mathbf y- \\hat{\\mathbf y}).（3.18）\n",
    "$$\n",
    "\n",
    "其中$\\mathbf X\\in \\mathbb{R}^{N\\times D}$为$N$个样本组成的矩阵，$\\mathbf y\\in \\mathbb{R}^{N}$为$N$个样本标签组成的向量，$\\hat{\\mathbf y}\\in \\mathbb{R}^{N}$为$N$个样本的预测标签组成的向量，$\\mathbf{1}$为$N$维的全1向量。\n",
    "\n",
    "将上述计算方法定义在模型的`backward`函数\n",
    "\n",
    "#### 对model类的理解\n",
    "\n",
    "不应让model本身存储输入的训练数据，model本身应该只是储存参数的，在何时何地，调用model，输入数据，输出预测结果，这才是model需要做的事情。\n",
    "\n",
    "训练过程，就是不断更新model中参数的过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33333333 0.33333333 0.33333333]\n",
      " [0.33333333 0.33333333 0.33333333]]\n",
      "{'W': array([[[ 0.83333333,  0.83333333, -1.66666667],\n",
      "        [ 1.83333333,  1.83333333, -3.66666667],\n",
      "        [ 1.5       ,  1.5       , -3.        ],\n",
      "        [ 2.        ,  2.        , -4.        ]],\n",
      "\n",
      "       [[-1.66666667,  0.83333333,  0.83333333],\n",
      "        [-3.66666667,  1.83333333,  1.83333333],\n",
      "        [-3.        ,  1.5       ,  1.5       ],\n",
      "        [-4.        ,  2.        ,  2.        ]]]), 'b': array([[ 0.33333333,  0.33333333, -0.66666667],\n",
      "       [-0.66666667,  0.33333333,  0.33333333]])}\n"
     ]
    }
   ],
   "source": [
    "class model_SR():\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        self.params = {}\n",
    "        self.params['W'] = np.zeros(shape=[input_dim, output_dim])\n",
    "        self.params['b'] = np.zeros(shape=[output_dim])\n",
    "        self.grads = {}\n",
    "        self.grads['W'] = None\n",
    "        self.grads['b'] = None\n",
    "        self.X = None\n",
    "        self.output = None\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def __call__(self, input):\n",
    "        return self.forward(input)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        输入：\n",
    "            - inputs: shape=[N,D], N是样本数量，D是特征维度\n",
    "        输出：\n",
    "            - outputs：预测值，shape=[N,C]，C是类别数\n",
    "\n",
    "        此处仅计算，最终的预测分类以及评估放在accuracy函数中\n",
    "        \"\"\"\n",
    "        self.X = input\n",
    "        score = np.matmul(self.X, self.params['W']) + self.params['b']\n",
    "        self.output = softmax(score)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, labels):\n",
    "        \"\"\"\n",
    "        输入：\n",
    "            - labels：真实标签，shape=[N, 1]，其中N为样本数量\n",
    "\n",
    "        计算交叉熵损失函数对模型各参数的偏导数，用于后续optimizer类更新参数\n",
    "\n",
    "        偏导数此处利用数学知识人为计算，还需要仔细思考为什么\n",
    "        \"\"\"\n",
    "        N = labels.shape[0]\n",
    "        labels = np.eye(self.output_dim)[labels]\n",
    "        self.grads['W'] = -1 / N * np.matmul(self.X.T, (labels-self.output))\n",
    "        self.grads['b'] = -1 / N * \\\n",
    "            np.matmul(np.ones(shape=[N]), (labels-self.output))\n",
    "\n",
    "\n",
    "# 测试\n",
    "a = np.array([[1, 2, 4, 6], [4, 9, 5, 6]])\n",
    "test_model = model_SR(input_dim=4, output_dim=3)\n",
    "test_result = test_model(a)\n",
    "test_labels = np.array([[2], [0]])\n",
    "test_model.backward(test_labels)\n",
    "print(test_result)\n",
    "print(test_model.grads)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 损失函数\n",
    "使用交叉熵损失函数\n",
    "\n",
    "一般来说，其也应该被包含在模型内，在模型调用backward方法时，自动计算损失函数对不同参数的偏导数\n",
    "\n",
    "但是本案例模型简单，即用数学方法直接计算了偏导数，损失函数也只是单纯进行计算记录，并不与模型(model)产生关联"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiCrossEntropyLoss():\n",
    "    def __init__(self):\n",
    "        self.predicts = None\n",
    "        self.labels = None\n",
    "        self.num = None\n",
    "\n",
    "    def __call__(self, predicts, labels):\n",
    "        return self.forward(predicts, labels)\n",
    "\n",
    "    def forward(self, predicts, labels):\n",
    "        \"\"\"\n",
    "        输入：\n",
    "            - predicts：预测值，shape=[N, D]，N为样本数量, D 为 类别数量 \n",
    "            - labels：真实标签，shape=[N, 1]\n",
    "        输出：\n",
    "            - 损失值：shape=[1]\n",
    "        \"\"\"\n",
    "        # print(\"debug: predicts.shape:\", predicts.shape)\n",
    "        self.predicts = predicts\n",
    "        self.labels = labels\n",
    "        self.num = self.predicts.shape[0]\n",
    "        loss = 0\n",
    "        for i in range(0, self.num):\n",
    "            index = int(self.labels[i].item())\n",
    "            # print(\"debug here: index = \", index)\n",
    "            # print(\"debug here: self.predicts[i] = \",self.predicts[i],self.predicts[i].shape)\n",
    "            # print(\"debug:\",type(i),type(index))\n",
    "            loss -= np.log(np.squeeze(self.predicts[i])[index])\n",
    "        return loss / self.num\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优化器 Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BGD_optimizer():\n",
    "    def __init__(self, lr, model):\n",
    "        self.lr = lr\n",
    "        self.model = model\n",
    "\n",
    "    def step(self):\n",
    "        if isinstance(self.model.params, dict):\n",
    "            for key in self.model.params.keys():\n",
    "                self.params[key] = self.params[key] - \\\n",
    "                    self.lr * self.model.grad[key]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评价与评价指标 metric\n",
    "\n",
    "使用accuracy, 在此函数中，输入每批次N个向量的output矩阵和label标签，将output矩阵转化为预测类别的一维向量，并计算accuracy，作为评价指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "def accuracy(output, labels):\n",
    "    '''\n",
    "    输入：\n",
    "        - output [N,C] , C 为可能的类别数量\n",
    "        - labels [N,1] \n",
    "    '''\n",
    "    preds = np.argmax(output, axis=1)\n",
    "    preds = np.squeeze(preds)\n",
    "    labels = np.squeeze(labels)\n",
    "    preds = np.array(preds,dtype = 'int32')\n",
    "    labels = np.array(labels, dtype = 'int32')\n",
    "    return np.mean(np.equal(preds, labels))\n",
    "\n",
    "\n",
    "# 测试\n",
    "output = np.array([[0.2, 0.2, 0.6], [0.3, 0.6, 0.1]])\n",
    "# labels = np.array([2,2])    两种输入都可以接受,内部使用了squeeze\n",
    "labels = np.array([[2], [2]],dtype = \"int64\")\n",
    "print(accuracy(output, labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runner 类 的封装\n",
    "实现Runner类（针对整批量梯度下降法）\n",
    "\n",
    "Runner类应将各种操作封装好，包括train, evaluate, pred等等，并且在训练过程中适当输出\n",
    "\n",
    "Runner类应该具有通用性，在实例化时指定需要的model，optimizer，metric，loss_fn这四个参数\n",
    "\n",
    "对于不同的模型，优化器，只需要在实例化时指定不同的参数即可\n",
    "\n",
    "实例化后，在train等方法中，再传入训练数据和标签\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runner():\n",
    "    def __init__(self, model, optimizer, metric, loss_fn):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.metric = metric\n",
    "        self.loss_fn = loss_fn\n",
    "        # 记录训练过程中的评价指标变化情况\n",
    "        self.train_scores = []\n",
    "        self.valid_scores = []\n",
    "        # 记录训练过程中的损失函数变化情况\n",
    "        self.train_loss = []\n",
    "        self.valid_loss = []\n",
    "        self.best_score = 0\n",
    "\n",
    "    def train(self, X_train, y_train, X_valid, y_valid, **kwargs):\n",
    "        num_epochs = kwargs.get(\"num_epochs\", 0)\n",
    "        # 传入训练记录的打印频率，如果没有传入值则默认为100\n",
    "        log_epochs = kwargs.get(\"log_epochs\", 100)\n",
    "        # 传入模型保存路径，如果没有传入值则默认为\"best_model.ppy\"\n",
    "        save_path = kwargs.get(\"save_path\", \"best_model.npy\")\n",
    "        for epoch in range(num_epochs):\n",
    "            # 前向计算\n",
    "            train_output = self.model(X_train)\n",
    "            valid_output = self.model(X_valid)\n",
    "            train_loss = self.loss_fn(train_output, y_train)\n",
    "            valid_loss = self.loss_fn(valid_output, y_valid)\n",
    "            train_score = self.metric(train_output, y_train)\n",
    "            valid_score = self.metric(valid_output, y_valid)\n",
    "            self.train_loss.append(train_loss)\n",
    "            self.valid_loss.append(valid_loss)\n",
    "            self.train_scores.append(train_score)\n",
    "            self.valid_loss.append(valid_score)\n",
    "\n",
    "            # 反向传播\n",
    "            self.model.backward(y_train)\n",
    "\n",
    "            # 更新参数\n",
    "            self.optimizer.step()\n",
    "\n",
    "            # 打印输出\n",
    "            if valid_score > self.best_score:\n",
    "                print(\n",
    "                    f\"best accuracy performence has been updated: {self.best_score:.5f} --> {valid_score:.5f}\")\n",
    "                self.best_score = valid_score\n",
    "            if epoch % log_epochs == 0:\n",
    "                print(\n",
    "                    f\"[Train] epoch: {epoch}, loss: {train_loss}, score: {train_score}\")\n",
    "                print(\n",
    "                    f\"[Dev] epoch: {epoch}, loss: {valid_loss}, score: {valid_score}\")\n",
    "\n",
    "    def predict(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def save_model(self, save_path):\n",
    "        np.save(save_path, self.model.params)\n",
    "        \n",
    "    def load_model(self, load_path):\n",
    "        return np.load(load_path, allow_pickle= True).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1dab970234817e839cad4d471145ff4cf7d30605deb6d374ecf32d0e4df6c0f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
