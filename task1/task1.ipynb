{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP -Beginner 任务1 基于机器学习的文本分类\n",
    "实现基于logistic/softmax regression的文本分类\n",
    "1. 参考\n",
    "   1. [文本分类](文本分类.md)\n",
    "   2. 《[神经网络与深度学习](https://nndl.github.io/)》 第2/3章\n",
    "2. 数据集：[Classify the sentiment of sentences from the Rotten Tomatoes dataset](https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews)\n",
    "3. 实现要求：NumPy\n",
    "4. 需要了解的知识点：\n",
    "\n",
    "   1. 文本特征表示：Bag-of-Word，N-gram\n",
    "   2. 分类器：logistic/softmax  regression，损失函数、（随机）梯度下降、特征选择\n",
    "   3. 数据集：训练集/验证集/测试集的划分\n",
    "5. 实验：\n",
    "   1. 分析不同的特征、损失函数、学习率对最终分类性能的影响\n",
    "   2. shuffle 、batch、mini-batch \n",
    "6. 时间：两周"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化 \n",
    "导入相应数据，模块包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import random\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "with open('train.tsv') as f:\n",
    "    tsvreader = csv.reader(f, delimiter='\\t')\n",
    "    temp = list(tsvreader)\n",
    "\n",
    "\n",
    "\n",
    "# 初始化\n",
    "raw_data = temp[1:]  # 忽略了表头\n",
    "raw_data = np.array(raw_data)[:,2:]\n",
    "max_item = 1000      # 提取前max_item个数据，否则数据量太大 BoWs就有150000*16000的矩阵\n",
    "raw_data = raw_data[:max_item,:]\n",
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader类\n",
    "目标：实现DataLoader类，将数据集根据Bag of Words 模型或者 N-gram 模型， 转化为特征向量和标签的形式,以X和y返回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 363)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, raw_data, method = 'BoWs'):\n",
    "        self.raw_data = raw_data\n",
    "        self.method = method\n",
    "        self.words_dict = dict()\n",
    "        self.len = 0\n",
    "        self.X = None\n",
    "        self.y = self.raw_data[:,-1]    # 这是标签\n",
    "        self.N = raw_data.shape[0]    # 数据集的sentence条目\n",
    "    \n",
    "    def __call__(self):\n",
    "        self.get_words()\n",
    "        if self.method == 'BoWs':\n",
    "            self.BoWs()\n",
    "        elif self.method == \"N_grams\":\n",
    "            self.N_grams()\n",
    "        else:\n",
    "            raise Exception('Wrong method, please use BoWs or N_grams')\n",
    "        return self.X,self.y\n",
    "        \n",
    "        \n",
    "    def get_words(self):\n",
    "        '''\n",
    "        统计所有出现的词数量,构建词典\n",
    "        '''\n",
    "        for item in self.raw_data:\n",
    "            s = item[0]\n",
    "            s = s.upper()   # 大小写统一是合理并且必要的\n",
    "            s = s.split()\n",
    "            for word in s:\n",
    "                if word not in self.words_dict:\n",
    "                    self.words_dict[word] = len(self.words_dict)    # 漂亮的一步（参考）：单词在词典中的值与自然数集对应，从而变为其在特征矩阵中的下表\n",
    "        self.len = len(self.words_dict)\n",
    "        self.X = np.zeros((self.N,self.len))    # 初始化特征矩阵\n",
    "    \n",
    "    def BoWs(self):\n",
    "        for i in range(self.N):\n",
    "            s = self.raw_data[i][0]\n",
    "            s = s.upper()\n",
    "            s = s.split()\n",
    "            for word in s:\n",
    "                self.X[i][self.words_dict[word]] += 1\n",
    "            \n",
    "    def N_grams():\n",
    "        pass\n",
    "\n",
    "\n",
    "# 测试一下\n",
    "dataloader = DataLoader(raw_data,method='BoWs')\n",
    "X, y = dataloader()\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 363) (200, 363) (800,) (200,)\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "\n",
    "\n",
    "def train_valid_split(X, y, train_percent=0.8):\n",
    "    '''\n",
    "    输入处理好的数据，随机打乱，返回 X_train, X_valid, y_train, y_valid\n",
    "    '''\n",
    "    n = len(X)\n",
    "    indices = list(range(n))\n",
    "    random.shuffle(indices)\n",
    "    X = X[indices]\n",
    "    y = y[indices]\n",
    "    train_num = int(n*train_percent)\n",
    "    X_train = X[:train_num,:]\n",
    "    X_valid = X[train_num:]\n",
    "    y_train = y[:train_num]\n",
    "    y_valid = y[train_num:]\n",
    "    return X_train, X_valid, y_train, y_valid\n",
    "\n",
    "# 测试一下\n",
    "X_train, X_valid, y_train, y_valid = train_valid_split(X,y)\n",
    "print(X_train.shape,X_valid.shape,y_train.shape,y_valid.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1dab970234817e839cad4d471145ff4cf7d30605deb6d374ecf32d0e4df6c0f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
